---
layout: post
title: 文本分析
date: 2020-04-26
tags: TATM
---
## 文本分析

​		词法分析：

正向最大匹配分词：长词优先原则。我们先去词库里面去搜索最长的字串（比如10个），然后去文本中直接截取10个字，看看是不是词。然后依次减少9，8，7。可以正向最大匹配，也可以反向最大匹配（需要词表配合，树状词表）。

​		Factor词：仿词

​		ELUS规则（类似于正则的一个词）



​		词网格是将所有备选候选词，都标记出来。在词网格中寻找最少分词就是寻找最短路径（也就是路径上的节点最小的路径）。穷举方法，去寻找最短路径（后面会讲解）。（实践证明这个方法效果会好于BM，向后最大算法，同时会好于正向最大匹配算法。）

​		如果词网格中含有仿词，那么直接将仿词当作一个格子。

​		优点：简单高效，缺点：缺少上下文环境。



N-gram模型：$P(S) = \prod^{n}_{i=1}P(w_i|w_{i-1})$此处就是去寻找联合概率最大的事情。如果我们直接统计n个词组成一个很大的语料库的时候，这个时候我们就会面临数据稀疏的问题。实际上这是一个简化的版本，如果直接按照条件概率去计算那么我们将会计算出来一个基本上都是0的数值。因此我们做这样的假设，每一次只取决上一个词。

N-gram模型其实质是N-1阶马尔科夫模型，时间不变特征（无论词放在句头，句尾概率都是一样的），水平有限特征（只受前面几个词的影响）。如果只受前面一个词的影响则为bigram模型，如果只受前面两个词那么为trigram模型。

我们将从前一个点到后一个节点的概率称为转移概率。包含类的计算的时候，将类型作为转移概率。

tri-gram比bigram的特点：

1.收到前两个词的约束影响；2.数据稀疏严重，3.参数空间大，4.计算量和储存空间大。



N-gram计算的方法计算细节：

1.全局寻优：

2.Viterbi算法：（这是一个局部最优方法，这个是动态规划问题。）此处来自于知乎如何通俗的理解viterbi算法第一个回答，href：https://www.zhihu.com/question/20136144

![image-20200422231059097](/Users/maxuan/Library/Application Support/typora-user-images/image-20200422231059097.png)

通俗的理解就是我们要寻找句子组成概率最大的那个组合，此处使用的就是，首先看，S处的概率是1，然后A1，A2，A3处的概率为P(A1),P(A2),P(A3)，然后我们去思考到达B1，B2，B3处的最大可能性。首先是B1，这个地方，max(P(A1)$\times$P(B1|A1), P(A2)$\times$P(B1|A2), P(B1|A3))。同样的道理我们可以得到B2，B3处的概率，然后我们就可以通过的得到的B1，B2，B3概率去计算C1，C2，C3处的概率。最后得到S到E处的最大概率组合。

